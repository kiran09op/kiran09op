# In this code i manually provided  all the functions are  working. So in the training time be careful, your one mistake can distroy the speed and efficiancy of the REVA.
from __future__ import with_statement
import pyttsx3
import speech_recognition as sr
import datetime
import wikipedia
import webbrowser                              # here line no2 to line no16 all are the basic libraries used in REVA
import os
import random
import cv2
import pywhatkit as kit
import sys
import pyautogui
import time
import operator
import requests

engine = pyttsx3.init('sapi5')
voices = engine.getProperty('voices')
engine.setProperty('voice', voices[1].id)  # Setting the voice to the second voice in the list (typically female)
engine.setProperty('rate', 150)

def speak(audio):
    engine.say(audio)
    engine.runAndWait()

def wishMe():
    hour = int(datetime.datetime.now().hour)
    if hour >= 0 and hour < 12:
        speak("Good Morning!")
    elif hour >= 12 and hour < 18:               # wishMe() is a built in function in python wishes stored as time perspective.
        speak("Good Afternoon!")
    else:
        speak("Good Evening!")
    speak("Ready To Comply. What can I do for you?")

def takeCommand():
    r = sr.Recognizer()
    with sr.Microphone() as source:
        print("Listening...")
        r.pause_threshold = 1
        audio = r.listen(source)
    try:
        print("Recognizing...") 
        query = r.recognize_google(audio, language='en-in')
        print(f"User said: {query}\n")
    except Exception as e: 
        print("Say that again please...") 
        return "None"
    return query

if __name__ == "__main__":
    wishMe()
    while True:
        query = takeCommand().lower()
        
        # Functionality from the new program
        if 'open chrome' in query:
            img = pyautogui.locateCenterOnScreen('Screenshot1.png')  # Take a screenshot of chrome and crop it, then save the image in the jarvis folder
            pyautogui.doubleClick(img)
            time.sleep(1)
            pyautogui.hotkey('alt', 'space')
            time.sleep(1)
            pyautogui.press('x')
            time.sleep(1)
            img1 = pyautogui.locateCenterOnScreen('screenshot2.png')  # Take a screenshot where you want to make the click
            pyautogui.click(img1)
            time.sleep(2)
            img2 = pyautogui.locateCenterOnScreen('screenshot3.png')
            pyautogui.click(img2)
            time.sleep(1)
            pyautogui.typewrite('How To Manual', 0.1)
            pyautogui.press('enter')
            time.sleep(1)
            pyautogui.press('esc')
            img3 = pyautogui.locateCenterOnScreen('screenshot4.png')
            pyautogui.click(img3)
        elif 'close chrome' in query:
            os.system("taskkill /f /im chrome.exe")
        
        # Existing functionalities
        elif 'wikipedia' in query:
            speak('Searching Wikipedia...')
            query = query.replace("wikipedia", "")
            results = wikipedia.summary(query, sentences=2)
            speak("According to Wikipedia")
            print(results)
            speak(results)
        elif "channel analytics" in query:
            webbrowser.open("https://studio.youtube.com/channel/UCxeYbp9rU_HuIwVcuHvK0pw/analytics/tab-overview/period-default")
        elif 'search on youtube' in query:
            query = query.replace("search on youtube", "")
            webbrowser.open(f"www.youtube.com/results?search_query={query}")
        elif 'open youtube' in query:
            speak("What would you like to watch?")
            qrry = takeCommand().lower()
            kit.playonyt(f"{qrry}")
        elif 'open google' in query:
            speak("What should I search?")
            qry = takeCommand().lower()
            webbrowser.open(f"{qry}")
            results = wikipedia.summary(qry, sentences=2)
            speak(results)
        elif 'close google' in query:
            os.system("taskkill /f /im msedge.exe")
        elif 'play music' in query:
            music_dir = 'E:\\Musics'
            songs = os.listdir(music_dir)
            os.startfile(os.path.join(music_dir, random.choice(songs)))
        elif 'play iron man movie' in query:
            npath = "E:\\ironman.mkv"
            os.startfile(npath)
        elif 'close movie' in query or 'close music' in query:
            os.system("taskkill /f /im vlc.exe")
        elif 'the time' in query:
            strTime = datetime.datetime.now().strftime("%H:%M:%S")
            speak(f"Sir, the time is {strTime}")
        elif "shut down the system" in query:
            speak("Shutting down the device. Goodbye!")
            os.system("shutdown /s /t 5")
        elif "restart the system" in query:
            speak("Restarting the device. See you in a moment!")
            os.system("shutdown /r /t 5")
        elif "lock the system" in query:
            speak("Locking the device.")
            os.system("rundll32.exe user32.dll,LockWorkStation")
        elif "close notepad" in query:
            os.system("taskkill /f /im notepad.exe")
        elif "open command prompt" in query:
            os.system("start cmd")
        elif "close command prompt" in query:
            os.system("taskkill /f /im cmd.exe")
        elif "open camera" in query:
            cap = cv2.VideoCapture(0)
            while True:
                ret, img = cap.read()
                cv2.imshow('webcam', img)
                k = cv2.waitKey(50)
                if k == 27:
                    break
            cap.release()
            cv2.destroyAllWindows()
        elif "go to sleep" in query:
            speak('Alright then, I am switching off')
            sys.exit()
        elif "take screenshot" in query:
            speak('Tell me a name for the file')
            name = takeCommand().lower()
            time.sleep(3)
            img = pyautogui.screenshot()
            img.save(f"{name}.png")
            speak("Screenshot saved")
        elif "calculate" in query:
            r = sr.Recognizer()
            with sr.Microphone() as source:
                speak("Ready")
                print("Listening...")
                r.adjust_for_ambient_noise(source)
                audio = r.listen(source)
                my_string = r.recognize_google(audio)
                print(my_string)
            def get_operator_fn(op):
                return {
                    '+' : operator.add,
                    '-' : operator.sub,
                    'x' : operator.mul,
                    'divided' : operator.truediv,
                }[op]
            def eval_binary_expr(op1, oper, op2):
                op1, op2 = int(op1), int(op2)
                return get_operator_fn(oper)(op1, op2)
            speak("Your result is")
            speak(eval_binary_expr(*(my_string.split())))
        elif "ip address" in query:
            ip = requests.get('https://api64.ipify.org').text
            print(ip)
            speak(f"Your IP address is {ip}")
        elif 'volume up' in query:
            pyautogui.press("volumeup")
        elif 'volume down' in query:
            pyautogui.press("volumedown")
        elif 'mute' in query:
            pyautogui.press("volumemute")
        elif 'refresh the browser' in query:
            pyautogui.hotkey("ctrl", "r")
        elif 'scroll down' in query:
            pyautogui.press("pagedown")
        elif 'draw' in query:
            import time
            import pyautogui
            time.sleep(2)
            pyautogui.click()
            distance = 200
            while distance > 0:
                pyautogui.dragRel(distance, 0, duration=0.5)
                distance -= 5
                pyautogui.dragRel(0, distance, duration=0.5)
                pyautogui.dragRel(-distance, 0, duration=0.5)
                distance -= 5
                pyautogui.dragRel(0, -distance, duration=0.5)
        elif "what is your name" in query:
            speak("My name is REVA.")
        elif "who created you" in query:
            speak("I was created by Kiran Nandani.")
        elif "write a note" in query:
            speak("What should I write?")
            note = takeCommand()
            file = open('note.txt', 'w')
            speak("Should I include date and time?")
            ans = takeCommand()
            if 'yes' in ans or 'sure' in ans:
                strTime = datetime.datetime.now().strftime("%H:%M:%S")
                file.write(strTime)
                file.write(" :- ")
                file.write(note)
            else:
                file.write(note)


